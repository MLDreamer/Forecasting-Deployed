{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG+69M7gasC4oXBROcXfn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLDreamer/Forecasting-Deployed/blob/main/Diebold_Mariano_in_Intermittent_TS_setting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intermittent Demand Forecasting with Diebold-Mariano Testing\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import lightgbm as lgb\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class IntermittentDataGenerator:\n",
        "    def __init__(self, seed: int = 42):\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    def spare_parts_demand(self, n: int = 200, occurrence_prob: float = 0.12) -> np.ndarray:\n",
        "        demand_occurs = np.random.binomial(1, occurrence_prob, n)\n",
        "        demand_size = np.random.lognormal(mean=2.5, sigma=0.9, size=n)\n",
        "        return demand_occurs * demand_size\n",
        "\n",
        "    def pharmaceutical_demand(self, n: int = 200) -> np.ndarray:\n",
        "        t = np.arange(n)\n",
        "        seasonal_prob = 0.15 + 0.08 * np.sin(2 * np.pi * t / 52)\n",
        "        seasonal_prob = np.clip(seasonal_prob, 0.05, 0.35)\n",
        "        demand_occurs = np.random.binomial(1, seasonal_prob, n)\n",
        "        demand_size = np.random.gamma(2, 25, n)\n",
        "        return demand_occurs * demand_size\n",
        "\n",
        "    def luxury_electronics(self, n: int = 200) -> np.ndarray:\n",
        "        demand = np.zeros(n)\n",
        "        launch_points = np.random.choice(range(20, n-20), 3, replace=False)\n",
        "\n",
        "        for launch in launch_points:\n",
        "            spike_duration = 15\n",
        "            for i in range(spike_duration):\n",
        "                if launch + i < n:\n",
        "                    prob = 0.7 * np.exp(-i/5)\n",
        "                    if np.random.random() < prob:\n",
        "                        demand[launch + i] = np.random.lognormal(3, 0.5)\n",
        "\n",
        "        background = np.random.binomial(1, 0.05, n) * np.random.lognormal(2, 0.3, n)\n",
        "        return demand + background\n",
        "\n",
        "class IntermittentMetrics:\n",
        "    @staticmethod\n",
        "    def mase(actual: np.ndarray, forecast: np.ndarray, seasonal_period: int = 1) -> float:\n",
        "        if len(actual) <= seasonal_period:\n",
        "            return np.inf\n",
        "        naive_errors = np.abs(np.diff(actual))\n",
        "        if np.mean(naive_errors) == 0:\n",
        "            return 0 if np.mean(np.abs(actual - forecast)) == 0 else np.inf\n",
        "        return np.mean(np.abs(actual - forecast)) / np.mean(naive_errors)\n",
        "\n",
        "    @staticmethod\n",
        "    def hit_rate(actual: np.ndarray, forecast: np.ndarray, tolerance: float = 0.1) -> float:\n",
        "        forecast = np.asarray(forecast)\n",
        "\n",
        "        non_zero_mask = actual > 0\n",
        "        if np.sum(non_zero_mask) == 0:\n",
        "            return 1.0\n",
        "        hits = np.abs(actual[non_zero_mask] - forecast[non_zero_mask]) <= tolerance * actual[non_zero_mask]\n",
        "        return np.mean(hits)\n",
        "\n",
        "    @staticmethod\n",
        "    def demand_classification_accuracy(actual: np.ndarray, forecast: np.ndarray, threshold: float = 0.5) -> float:\n",
        "\n",
        "        forecast = np.asarray(forecast)\n",
        "        actual_demand_occurs = (actual > threshold).astype(int)\n",
        "        forecast_demand_occurs = (forecast > threshold).astype(int)\n",
        "        return np.mean(actual_demand_occurs == forecast_demand_occurs)\n",
        "\n",
        "    @staticmethod\n",
        "    def periods_in_stock(actual: np.ndarray, forecast: np.ndarray) -> float:\n",
        "        forecast = np.asarray(forecast)\n",
        "        return np.mean(forecast >= actual)\n",
        "\n",
        "    @staticmethod\n",
        "    def scaled_pinball_loss(actual: np.ndarray, forecast: np.ndarray, quantile: float = 0.5) -> float:\n",
        "        forecast = np.asarray(forecast)\n",
        "        errors = actual - forecast\n",
        "        loss = np.maximum(quantile * errors, (quantile - 1) * errors)\n",
        "        scale = np.mean(actual) if np.mean(actual) > 0 else 1\n",
        "        return np.mean(loss) / scale\n",
        "\n",
        "class IntermittentForecastingMethods:\n",
        "    @staticmethod\n",
        "    def croston_method(series: np.ndarray, alpha: float = 0.1) -> float:\n",
        "        non_zero_indices = np.where(series > 0)[0]\n",
        "\n",
        "        if len(non_zero_indices) < 2:\n",
        "            return np.mean(series[series > 0]) if np.any(series > 0) else 0\n",
        "\n",
        "        z_hat = series[non_zero_indices[0]]\n",
        "        x_hat = non_zero_indices[1] - non_zero_indices[0]\n",
        "\n",
        "        for i in range(1, len(non_zero_indices)):\n",
        "            current_demand = series[non_zero_indices[i]]\n",
        "            current_interval = non_zero_indices[i] - non_zero_indices[i-1]\n",
        "\n",
        "            z_hat = alpha * current_demand + (1 - alpha) * z_hat\n",
        "            x_hat = alpha * current_interval + (1 - alpha) * x_hat\n",
        "\n",
        "        return z_hat / x_hat if x_hat > 0 else 0\n",
        "\n",
        "    @staticmethod\n",
        "    def tsb_method(series: np.ndarray, alpha: float = 0.1, beta: float = 0.1) -> float:\n",
        "        non_zero_indices = np.where(series > 0)[0]\n",
        "\n",
        "        if len(non_zero_indices) < 3:\n",
        "            return IntermittentForecastingMethods.croston_method(series, alpha)\n",
        "\n",
        "        intervals = np.diff(non_zero_indices)\n",
        "        cv_squared = (np.std(intervals) / np.mean(intervals)) ** 2 if np.mean(intervals) > 0 else 0\n",
        "\n",
        "        bias_correction = (2 - alpha) / (2 - alpha + alpha * cv_squared)\n",
        "        croston_forecast = IntermittentForecastingMethods.croston_method(series, alpha)\n",
        "\n",
        "        return croston_forecast * bias_correction\n",
        "\n",
        "    @staticmethod\n",
        "    def lgbm_standard(series: np.ndarray, window: int = 12) -> float:\n",
        "        if len(series) < window + 5:\n",
        "            return np.mean(series)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(window, len(series)):\n",
        "            window_data = series[i-window:i]\n",
        "\n",
        "            features = [\n",
        "                *window_data[-6:],\n",
        "                np.sum(window_data > 0),\n",
        "                np.mean(window_data[window_data > 0]) if np.any(window_data > 0) else 0,\n",
        "                np.std(window_data),\n",
        "                np.max(window_data),\n",
        "                np.mean(np.diff(window_data)),\n",
        "                np.sum(window_data[-3:] > 0),\n",
        "                len(window_data) - np.where(window_data > 0)[0][-1] if np.any(window_data > 0) else len(window_data)\n",
        "            ]\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(series[i])\n",
        "\n",
        "        if len(X) < 10:\n",
        "            return np.mean(series)\n",
        "\n",
        "        model = lgb.LGBMRegressor(\n",
        "            objective='regression',\n",
        "            n_estimators=50,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            feature_fraction=0.8,\n",
        "            bagging_fraction=0.8,\n",
        "            verbose=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(X, y)\n",
        "\n",
        "        last_window = series[-window:]\n",
        "        features = [\n",
        "            *last_window[-6:],\n",
        "            np.sum(last_window > 0),\n",
        "            np.mean(last_window[last_window > 0]) if np.any(last_window > 0) else 0,\n",
        "            np.std(last_window),\n",
        "            np.max(last_window),\n",
        "            np.mean(np.diff(last_window)),\n",
        "            np.sum(last_window[-3:] > 0),\n",
        "            len(last_window) - np.where(last_window > 0)[0][-1] if np.any(last_window > 0) else len(last_window)\n",
        "        ]\n",
        "\n",
        "        return max(0, model.predict([features])[0])\n",
        "\n",
        "    @staticmethod\n",
        "    def lgbm_tweedie(series: np.ndarray, window: int = 12) -> float:\n",
        "        if len(series) < window + 5:\n",
        "            return np.mean(series)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(window, len(series)):\n",
        "            window_data = series[i-window:i]\n",
        "\n",
        "            features = [\n",
        "                *window_data[-6:],\n",
        "                np.sum(window_data > 0),\n",
        "                np.mean(window_data[window_data > 0]) if np.any(window_data > 0) else 0,\n",
        "                np.std(window_data),\n",
        "                np.max(window_data),\n",
        "                np.mean(np.diff(window_data)),\n",
        "                np.sum(window_data[-3:] > 0),\n",
        "                len(window_data) - np.where(window_data > 0)[0][-1] if np.any(window_data > 0) else len(window_data)\n",
        "            ]\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(series[i])\n",
        "\n",
        "        if len(X) < 10:\n",
        "            return np.mean(series)\n",
        "\n",
        "        model = lgb.LGBMRegressor(\n",
        "            objective='tweedie',\n",
        "            tweedie_variance_power=1.5,\n",
        "            n_estimators=50,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            feature_fraction=0.8,\n",
        "            bagging_fraction=0.8,\n",
        "            verbose=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(X, y)\n",
        "\n",
        "        last_window = series[-window:]\n",
        "        features = [\n",
        "            *last_window[-6:],\n",
        "            np.sum(last_window > 0),\n",
        "            np.mean(last_window[last_window > 0]) if np.any(last_window > 0) else 0,\n",
        "            np.std(last_window),\n",
        "            np.max(last_window),\n",
        "            np.mean(np.diff(last_window)),\n",
        "            np.sum(last_window[-3:] > 0),\n",
        "            len(last_window) - np.where(last_window > 0)[0][-1] if np.any(last_window > 0) else len(last_window)\n",
        "        ]\n",
        "\n",
        "        return max(0, model.predict([features])[0])\n",
        "\n",
        "class DieboldMarianoFramework:\n",
        "    def __init__(self, loss_function: str = 'absolute'):\n",
        "        self.loss_function = loss_function\n",
        "        self.results_cache = {}\n",
        "\n",
        "    def _compute_loss_differential(self, errors1: np.ndarray, errors2: np.ndarray) -> np.ndarray:\n",
        "        if self.loss_function == 'absolute':\n",
        "            d = np.abs(errors1) - np.abs(errors2)\n",
        "        elif self.loss_function == 'squared':\n",
        "            d = errors1**2 - errors2**2\n",
        "        elif self.loss_function == 'asymmetric':\n",
        "            def asymmetric_loss(error):\n",
        "                return np.where(error > 0, 3 * error, -error)\n",
        "            d = asymmetric_loss(errors1) - asymmetric_loss(errors2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported loss function: {self.loss_function}\")\n",
        "\n",
        "        return d\n",
        "\n",
        "    def statistical_test(self, model1_name: str, model1_errors: np.ndarray,\n",
        "                        model2_name: str, model2_errors: np.ndarray) -> Dict:\n",
        "        cache_key = f\"{model1_name}_vs_{model2_name}_{self.loss_function}\"\n",
        "\n",
        "        if cache_key in self.results_cache:\n",
        "            return self.results_cache[cache_key]\n",
        "\n",
        "        d = self._compute_loss_differential(model1_errors, model2_errors)\n",
        "        n = len(d)\n",
        "\n",
        "        if n < 10:\n",
        "            return {\n",
        "                'test_statistic': 0,\n",
        "                'p_value': 1.0,\n",
        "                'significant': False,\n",
        "                'interpretation': 'Insufficient data for reliable test',\n",
        "                'sample_size': n\n",
        "            }\n",
        "\n",
        "        d_mean = np.mean(d)\n",
        "        gamma_0 = np.var(d, ddof=1)\n",
        "\n",
        "        if gamma_0 == 0:\n",
        "            result = {\n",
        "                'test_statistic': 0,\n",
        "                'p_value': 1.0,\n",
        "                'significant': False,\n",
        "                'interpretation': 'Models have identical performance',\n",
        "                'sample_size': n\n",
        "            }\n",
        "        else:\n",
        "            dm_stat = d_mean / np.sqrt(gamma_0 / n)\n",
        "            p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
        "\n",
        "            if p_value < 0.01:\n",
        "                significance = \"Highly significant\"\n",
        "                confidence = \"99%+\"\n",
        "            elif p_value < 0.05:\n",
        "                significance = \"Significant\"\n",
        "                confidence = \"95%+\"\n",
        "            elif p_value < 0.10:\n",
        "                significance = \"Marginally significant\"\n",
        "                confidence = \"90%+\"\n",
        "            else:\n",
        "                significance = \"Not significant\"\n",
        "                confidence = f\"{(1-p_value)*100:.1f}%\"\n",
        "\n",
        "            if p_value < 0.05:\n",
        "                winner = model1_name if dm_stat < 0 else model2_name\n",
        "                loser = model2_name if dm_stat < 0 else model1_name\n",
        "                business_rec = f\"Deploy {winner} - statistically superior to {loser}\"\n",
        "            else:\n",
        "                business_rec = \"No significant difference - consider other factors\"\n",
        "\n",
        "            result = {\n",
        "                'test_statistic': dm_stat,\n",
        "                'p_value': p_value,\n",
        "                'significant': p_value < 0.05,\n",
        "                'significance_level': significance,\n",
        "                'confidence': confidence,\n",
        "                'winner': winner if p_value < 0.05 else None,\n",
        "                'interpretation': f\"{significance} difference\",\n",
        "                'business_recommendation': business_rec,\n",
        "                'sample_size': n,\n",
        "                'mean_loss_diff': d_mean\n",
        "            }\n",
        "\n",
        "        self.results_cache[cache_key] = result\n",
        "        return result\n",
        "\n",
        "class IntermittentBenchmark:\n",
        "    def __init__(self):\n",
        "        self.methods = {\n",
        "            'Croston': IntermittentForecastingMethods.croston_method,\n",
        "            'TSB': IntermittentForecastingMethods.tsb_method,\n",
        "            'LGBM': IntermittentForecastingMethods.lgbm_standard,\n",
        "            'LGBM_Tweedie': IntermittentForecastingMethods.lgbm_tweedie\n",
        "        }\n",
        "\n",
        "        self.dm_framework = DieboldMarianoFramework(loss_function='absolute')\n",
        "        self.results = []\n",
        "        self.statistical_results = []\n",
        "\n",
        "    def evaluate_methods(self, data: np.ndarray, dataset_name: str):\n",
        "        split_point = int(0.8 * len(data))\n",
        "        train, test = data[:split_point], data[split_point:]\n",
        "\n",
        "        forecasts = {}\n",
        "        errors = {}\n",
        "        metrics = IntermittentMetrics()\n",
        "\n",
        "        for method_name, method_func in self.methods.items():\n",
        "            try:\n",
        "                method_forecasts = []\n",
        "                method_errors = []\n",
        "\n",
        "                for i in range(len(test)):\n",
        "                    if i == 0:\n",
        "                        current_train = train.copy()\n",
        "                    else:\n",
        "                        current_train = np.concatenate([train, test[:i]])\n",
        "\n",
        "                    if len(current_train) < 10:\n",
        "                        forecast = np.mean(current_train[current_train > 0]) if np.any(current_train > 0) else 0\n",
        "                    else:\n",
        "                        forecast = method_func(current_train)\n",
        "\n",
        "                    actual = test[i]\n",
        "                    method_forecasts.append(max(0, forecast))\n",
        "                    method_errors.append(actual - max(0, forecast))\n",
        "\n",
        "                forecasts[method_name] = np.array(method_forecasts)\n",
        "                errors[method_name] = np.array(method_errors)\n",
        "\n",
        "                mae = np.mean(np.abs(method_errors))\n",
        "                mase = metrics.mase(test, method_forecasts)\n",
        "                hit_rate = metrics.hit_rate(test, method_forecasts)\n",
        "                demand_acc = metrics.demand_classification_accuracy(test, method_forecasts)\n",
        "                periods_in_stock = metrics.periods_in_stock(test, method_forecasts)\n",
        "\n",
        "                self.results.append({\n",
        "                    'Dataset': dataset_name,\n",
        "                    'Method': method_name,\n",
        "                    'MAE': mae,\n",
        "                    'MASE': mase,\n",
        "                    'Hit_Rate': hit_rate,\n",
        "                    'Demand_Classification_Accuracy': demand_acc,\n",
        "                    'Periods_In_Stock': periods_in_stock\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {method_name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        method_names = list(errors.keys())\n",
        "        for i in range(len(method_names)):\n",
        "            for j in range(i + 1, len(method_names)):\n",
        "                method1, method2 = method_names[i], method_names[j]\n",
        "\n",
        "                result = self.dm_framework.statistical_test(\n",
        "                    method1, errors[method1],\n",
        "                    method2, errors[method2]\n",
        "                )\n",
        "\n",
        "                self.statistical_results.append({\n",
        "                    'Dataset': dataset_name,\n",
        "                    'Method1': method1,\n",
        "                    'Method2': method2,\n",
        "                    'DM_Statistic': result['test_statistic'],\n",
        "                    'P_Value': result['p_value'],\n",
        "                    'Significant': result['significant'],\n",
        "                    'Winner': result.get('winner', 'None'),\n",
        "                    'Business_Recommendation': result['business_recommendation']\n",
        "                })\n",
        "\n",
        "    def run_comprehensive_evaluation(self):\n",
        "        data_gen = IntermittentDataGenerator(seed=42)\n",
        "        datasets = {\n",
        "            'Automotive_Parts': data_gen.spare_parts_demand(n=200, occurrence_prob=0.12),\n",
        "            'Pharmaceutical': data_gen.pharmaceutical_demand(n=200),\n",
        "            'Luxury_Electronics': data_gen.luxury_electronics(n=200)\n",
        "        }\n",
        "\n",
        "        for dataset_name, data in datasets.items():\n",
        "            self.evaluate_methods(data, dataset_name)\n",
        "\n",
        "        results_df = pd.DataFrame(self.results)\n",
        "        stats_df = pd.DataFrame(self.statistical_results)\n",
        "\n",
        "        return results_df, stats_df\n",
        "\n",
        "def demonstrate_metric_inadequacy():\n",
        "    np.random.seed(123)\n",
        "    data_gen = IntermittentDataGenerator(seed=123)\n",
        "    demo_data = data_gen.spare_parts_demand(n=120, occurrence_prob=0.08)\n",
        "\n",
        "    split_point = int(0.8 * len(demo_data))\n",
        "    train, test = demo_data[:split_point], demo_data[split_point:]\n",
        "\n",
        "    croston_forecasts = []\n",
        "    lgbm_forecasts = []\n",
        "\n",
        "    for i in range(len(test)):\n",
        "        if i == 0:\n",
        "            current_train = train.copy()\n",
        "        else:\n",
        "            current_train = np.concatenate([train, test[:i]])\n",
        "\n",
        "        if len(current_train) < 10:\n",
        "            croston_forecast = np.mean(current_train[current_train > 0]) if np.any(current_train > 0) else 0\n",
        "            lgbm_forecast = croston_forecast\n",
        "        else:\n",
        "            croston_forecast = IntermittentForecastingMethods.croston_method(current_train)\n",
        "            lgbm_forecast = IntermittentForecastingMethods.lgbm_standard(current_train)\n",
        "\n",
        "        croston_forecasts.append(max(0, croston_forecast))\n",
        "        lgbm_forecasts.append(max(0, lgbm_forecast))\n",
        "\n",
        "    croston_errors = test - np.array(croston_forecasts)\n",
        "    lgbm_errors = test - np.array(lgbm_forecasts)\n",
        "\n",
        "    croston_mae = np.mean(np.abs(croston_errors))\n",
        "    lgbm_mae = np.mean(np.abs(lgbm_errors))\n",
        "\n",
        "    dm_test = DieboldMarianoFramework(loss_function='absolute')\n",
        "    result = dm_test.statistical_test('Croston', croston_errors, 'LGBM', lgbm_errors)\n",
        "\n",
        "    return {\n",
        "        'croston_mae': croston_mae,\n",
        "        'lgbm_mae': lgbm_mae,\n",
        "        'statistical_result': result,\n",
        "        'test_data': test,\n",
        "        'croston_forecasts': croston_forecasts,\n",
        "        'lgbm_forecasts': lgbm_forecasts\n",
        "    }\n",
        "\n",
        "def comprehensive_metric_comparison():\n",
        "    print(\"=\"*80)\n",
        "    print(\"WHY TRADITIONAL METRICS FAIL FOR INTERMITTENT TIME SERIES\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    np.random.seed(42)\n",
        "    data_gen = IntermittentDataGenerator(seed=42)\n",
        "\n",
        "    datasets = {\n",
        "        'Automotive_Parts': data_gen.spare_parts_demand(n=150, occurrence_prob=0.10),\n",
        "        'Pharmaceutical': data_gen.pharmaceutical_demand(n=150),\n",
        "        'Luxury_Electronics': data_gen.luxury_electronics(n=150)\n",
        "    }\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for dataset_name, data in datasets.items():\n",
        "        print(f\"\\n📊 DATASET: {dataset_name}\")\n",
        "        print(f\"Intermittency Rate: {np.sum(data == 0)/len(data)*100:.1f}% zeros\")\n",
        "\n",
        "        split_point = int(0.8 * len(data))\n",
        "        train, test = data[:split_point], data[split_point:]\n",
        "\n",
        "        methods = {\n",
        "            'Croston': IntermittentForecastingMethods.croston_method,\n",
        "            'TSB': IntermittentForecastingMethods.tsb_method,\n",
        "            'LGBM_Tweedie': IntermittentForecastingMethods.lgbm_tweedie\n",
        "        }\n",
        "\n",
        "        method_results = {}\n",
        "        method_errors = {}\n",
        "\n",
        "        for method_name, method_func in methods.items():\n",
        "            try:\n",
        "                forecasts = []\n",
        "                errors = []\n",
        "\n",
        "                for i in range(len(test)):\n",
        "                    if i == 0:\n",
        "                        current_train = train.copy()\n",
        "                    else:\n",
        "                        current_train = np.concatenate([train, test[:i]])\n",
        "\n",
        "                    if len(current_train) < 15:\n",
        "                        forecast = np.mean(current_train[current_train > 0]) if np.any(current_train > 0) else 0\n",
        "                    else:\n",
        "                        forecast = method_func(current_train)\n",
        "\n",
        "                    forecasts.append(max(0, forecast))\n",
        "                    errors.append(test[i] - max(0, forecast))\n",
        "\n",
        "                forecasts = np.array(forecasts)\n",
        "                errors = np.array(errors)\n",
        "\n",
        "                metrics = IntermittentMetrics()\n",
        "\n",
        "                result = {\n",
        "                    'Dataset': dataset_name,\n",
        "                    'Method': method_name,\n",
        "                    'MAE': np.mean(np.abs(errors)),\n",
        "                    'MASE': metrics.mase(test, forecasts),\n",
        "                    'Hit_Rate': metrics.hit_rate(test, forecasts, tolerance=0.15),\n",
        "                    'Demand_Accuracy': metrics.demand_classification_accuracy(test, forecasts),\n",
        "                    'Service_Level': metrics.periods_in_stock(test, forecasts),\n",
        "                    'Forecasts': forecasts,\n",
        "                    'Errors': errors\n",
        "                }\n",
        "\n",
        "                method_results[method_name] = result\n",
        "                method_errors[method_name] = errors\n",
        "                all_results.append(result)\n",
        "\n",
        "                print(f\"\\n{method_name}:\")\n",
        "                print(f\"  MAE: {result['MAE']:.3f}\")\n",
        "                print(f\"  MASE: {result['MASE']:.3f}\")\n",
        "                print(f\"  Hit Rate: {result['Hit_Rate']:.3f}\")\n",
        "                print(f\"  Demand Accuracy: {result['Demand_Accuracy']:.3f}\")\n",
        "                print(f\"  Service Level: {result['Service_Level']:.3f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ {method_name} failed: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if len(method_errors) >= 2:\n",
        "            print(f\"\\n🔬 DIEBOLD-MARIANO STATISTICAL TESTS:\")\n",
        "            dm_framework = DieboldMarianoFramework()\n",
        "\n",
        "            method_names = list(method_errors.keys())\n",
        "            for i in range(len(method_names)):\n",
        "                for j in range(i + 1, len(method_names)):\n",
        "                    method1, method2 = method_names[i], method_names[j]\n",
        "\n",
        "                    dm_result = dm_framework.statistical_test(\n",
        "                        method1, method_errors[method1],\n",
        "                        method2, method_errors[method2]\n",
        "                    )\n",
        "\n",
        "                    significance = \"✅ SIGNIFICANT\" if dm_result['significant'] else \"❌ NOT SIGNIFICANT\"\n",
        "                    winner_text = f\" → Winner: {dm_result.get('winner', 'None')}\" if dm_result['significant'] else \"\"\n",
        "\n",
        "                    print(f\"  {method1} vs {method2}: p={dm_result['p_value']:.4f} {significance}{winner_text}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def production_deployment_example():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PRODUCTION DEPLOYMENT DECISION FRAMEWORK\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    np.random.seed(100)\n",
        "    data_gen = IntermittentDataGenerator(seed=100)\n",
        "    prod_data = data_gen.spare_parts_demand(n=200, occurrence_prob=0.08)\n",
        "\n",
        "    split_point = int(0.8 * len(prod_data))\n",
        "    train, test = prod_data[:split_point], prod_data[split_point:]\n",
        "\n",
        "    current_model_forecasts = []\n",
        "    new_model_forecasts = []\n",
        "\n",
        "    for i in range(len(test)):\n",
        "        if i == 0:\n",
        "            current_train = train.copy()\n",
        "        else:\n",
        "            current_train = np.concatenate([train, test[:i]])\n",
        "\n",
        "        if len(current_train) < 15:\n",
        "            current_forecast = np.mean(current_train[current_train > 0]) if np.any(current_train > 0) else 0\n",
        "            new_forecast = current_forecast\n",
        "        else:\n",
        "            current_forecast = IntermittentForecastingMethods.croston_method(current_train)\n",
        "            new_forecast = IntermittentForecastingMethods.lgbm_tweedie(current_train)\n",
        "\n",
        "        current_model_forecasts.append(max(0, current_forecast))\n",
        "        new_model_forecasts.append(max(0, new_forecast))\n",
        "\n",
        "    current_errors = test - np.array(current_model_forecasts)\n",
        "    new_errors = test - np.array(new_model_forecasts)\n",
        "\n",
        "    print(f\"\\n📈 TRADITIONAL METRIC COMPARISON:\")\n",
        "    current_mae = np.mean(np.abs(current_errors))\n",
        "    new_mae = np.mean(np.abs(new_errors))\n",
        "    improvement = (current_mae - new_mae) / current_mae * 100\n",
        "\n",
        "    print(f\"Current Model (Croston) MAE: {current_mae:.4f}\")\n",
        "    print(f\"New Model (LGBM+Tweedie) MAE: {new_mae:.4f}\")\n",
        "    print(f\"Improvement: {improvement:.1f}%\")\n",
        "\n",
        "    if improvement > 0:\n",
        "        print(\"🎯 Traditional Decision: DEPLOY new model (better MAE)\")\n",
        "    else:\n",
        "        print(\"🎯 Traditional Decision: KEEP current model (better MAE)\")\n",
        "\n",
        "    metrics = IntermittentMetrics()\n",
        "    print(f\"\\n📊 PROPER INTERMITTENT METRICS:\")\n",
        "\n",
        "    current_mase = metrics.mase(test, current_model_forecasts)\n",
        "    new_mase = metrics.mase(test, new_model_forecasts)\n",
        "    current_hit_rate = metrics.hit_rate(test, current_model_forecasts)\n",
        "    new_hit_rate = metrics.hit_rate(test, new_model_forecasts)\n",
        "    current_service = metrics.periods_in_stock(test, current_model_forecasts)\n",
        "    new_service = metrics.periods_in_stock(test, new_model_forecasts)\n",
        "\n",
        "    print(f\"MASE - Current: {current_mase:.3f}, New: {new_mase:.3f}\")\n",
        "    print(f\"Hit Rate - Current: {current_hit_rate:.3f}, New: {new_hit_rate:.3f}\")\n",
        "    print(f\"Service Level - Current: {current_service:.3f}, New: {new_service:.3f}\")\n",
        "\n",
        "    dm_framework = DieboldMarianoFramework()\n",
        "    dm_result = dm_framework.statistical_test('Current_Model', current_errors, 'New_Model', new_errors)\n",
        "\n",
        "    print(f\"\\n🧮 DIEBOLD-MARIANO STATISTICAL TEST:\")\n",
        "    print(f\"Test Statistic: {dm_result['test_statistic']:.4f}\")\n",
        "    print(f\"P-value: {dm_result['p_value']:.6f}\")\n",
        "    print(f\"Significant at α=0.05: {dm_result['significant']}\")\n",
        "\n",
        "    if dm_result['significant']:\n",
        "        print(f\"Statistical Winner: {dm_result.get('winner', 'None')}\")\n",
        "        print(f\"Confidence Level: {dm_result.get('confidence', 'Unknown')}\")\n",
        "    else:\n",
        "        print(\"Result: NO statistically significant difference\")\n",
        "\n",
        "    print(f\"\\n💼 PRODUCTION DEPLOYMENT DECISION:\")\n",
        "    if dm_result['significant'] and dm_result['p_value'] < 0.01:\n",
        "        decision = f\"✅ DEPLOY {dm_result['winner']} - High Confidence (p < 0.01)\"\n",
        "        risk = \"Low risk deployment\"\n",
        "    elif dm_result['significant'] and dm_result['p_value'] < 0.05:\n",
        "        decision = f\"⚠️ DEPLOY {dm_result['winner']} - Medium Confidence (p < 0.05)\"\n",
        "        risk = \"Medium risk deployment - monitor closely\"\n",
        "    else:\n",
        "        decision = \"❌ DO NOT DEPLOY - Difference not statistically significant\"\n",
        "        risk = \"High risk - performance difference likely random noise\"\n",
        "\n",
        "    print(f\"Decision: {decision}\")\n",
        "    print(f\"Risk Assessment: {risk}\")\n",
        "    print(f\"Business Recommendation: {dm_result['business_recommendation']}\")\n",
        "\n",
        "    return {\n",
        "        'traditional_metrics': {'current_mae': current_mae, 'new_mae': new_mae, 'improvement': improvement},\n",
        "        'proper_metrics': {'mase_current': current_mase, 'mase_new': new_mase, 'hit_rate_current': current_hit_rate, 'hit_rate_new': new_hit_rate},\n",
        "        'statistical_result': dm_result,\n",
        "        'deployment_decision': decision\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🚀 INTERMITTENT TIME SERIES FORECASTING: METRICS THAT ACTUALLY MATTER\")\n",
        "\n",
        "    comprehensive_results = comprehensive_metric_comparison()\n",
        "\n",
        "    production_results = production_deployment_example()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"KEY TAKEAWAYS:\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"1. MAE alone is insufficient for intermittent time series\")\n",
        "    print(\"2. Use MASE, Hit Rate, and Service Level for business relevance\")\n",
        "    print(\"3. ALWAYS validate with Diebold-Mariano before deployment\")\n",
        "    print(\"4. Statistical significance prevents costly deployment mistakes\")\n",
        "    print(\"5. Proper metrics align with inventory management objectives\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH5orlhZKTv4",
        "outputId": "83f0d5c8-ad6b-465a-ac0e-9d84d74d6656"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 INTERMITTENT TIME SERIES FORECASTING: METRICS THAT ACTUALLY MATTER\n",
            "================================================================================\n",
            "WHY TRADITIONAL METRICS FAIL FOR INTERMITTENT TIME SERIES\n",
            "================================================================================\n",
            "\n",
            "📊 DATASET: Automotive_Parts\n",
            "Intermittency Rate: 90.7% zeros\n",
            "\n",
            "Croston:\n",
            "  MAE: 4.560\n",
            "  MASE: 0.730\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.100\n",
            "  Service Level: 0.900\n",
            "\n",
            "TSB:\n",
            "  MAE: 4.502\n",
            "  MASE: 0.721\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.100\n",
            "  Service Level: 0.900\n",
            "\n",
            "LGBM_Tweedie:\n",
            "  MAE: 4.235\n",
            "  MASE: 0.678\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.133\n",
            "  Service Level: 0.900\n",
            "\n",
            "🔬 DIEBOLD-MARIANO STATISTICAL TESTS:\n",
            "  Croston vs TSB: p=0.0000 ✅ SIGNIFICANT → Winner: TSB\n",
            "  Croston vs LGBM_Tweedie: p=0.0565 ❌ NOT SIGNIFICANT\n",
            "  TSB vs LGBM_Tweedie: p=0.1095 ❌ NOT SIGNIFICANT\n",
            "\n",
            "📊 DATASET: Pharmaceutical\n",
            "Intermittency Rate: 82.7% zeros\n",
            "\n",
            "Croston:\n",
            "  MAE: 19.621\n",
            "  MASE: 0.676\n",
            "  Hit Rate: 0.125\n",
            "  Demand Accuracy: 0.267\n",
            "  Service Level: 0.733\n",
            "\n",
            "TSB:\n",
            "  MAE: 19.191\n",
            "  MASE: 0.661\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.267\n",
            "  Service Level: 0.733\n",
            "\n",
            "LGBM_Tweedie:\n",
            "  MAE: 20.350\n",
            "  MASE: 0.701\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.267\n",
            "  Service Level: 0.733\n",
            "\n",
            "🔬 DIEBOLD-MARIANO STATISTICAL TESTS:\n",
            "  Croston vs TSB: p=0.0033 ✅ SIGNIFICANT → Winner: TSB\n",
            "  Croston vs LGBM_Tweedie: p=0.6703 ❌ NOT SIGNIFICANT\n",
            "  TSB vs LGBM_Tweedie: p=0.4852 ❌ NOT SIGNIFICANT\n",
            "\n",
            "📊 DATASET: Luxury_Electronics\n",
            "Intermittency Rate: 86.7% zeros\n",
            "\n",
            "Croston:\n",
            "  MAE: 3.108\n",
            "  MASE: 1.616\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.100\n",
            "  Service Level: 0.900\n",
            "\n",
            "TSB:\n",
            "  MAE: 2.945\n",
            "  MASE: 1.531\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.100\n",
            "  Service Level: 0.900\n",
            "\n",
            "LGBM_Tweedie:\n",
            "  MAE: 4.169\n",
            "  MASE: 2.167\n",
            "  Hit Rate: 0.000\n",
            "  Demand Accuracy: 0.300\n",
            "  Service Level: 0.900\n",
            "\n",
            "🔬 DIEBOLD-MARIANO STATISTICAL TESTS:\n",
            "  Croston vs TSB: p=0.0000 ✅ SIGNIFICANT → Winner: TSB\n",
            "  Croston vs LGBM_Tweedie: p=0.1238 ❌ NOT SIGNIFICANT\n",
            "  TSB vs LGBM_Tweedie: p=0.0762 ❌ NOT SIGNIFICANT\n",
            "\n",
            "================================================================================\n",
            "PRODUCTION DEPLOYMENT DECISION FRAMEWORK\n",
            "================================================================================\n",
            "\n",
            "📈 TRADITIONAL METRIC COMPARISON:\n",
            "Current Model (Croston) MAE: 4.4213\n",
            "New Model (LGBM+Tweedie) MAE: 3.2954\n",
            "Improvement: 25.5%\n",
            "🎯 Traditional Decision: DEPLOY new model (better MAE)\n",
            "\n",
            "📊 PROPER INTERMITTENT METRICS:\n",
            "MASE - Current: 4.918, New: 3.666\n",
            "Hit Rate - Current: 0.000, New: 0.250\n",
            "Service Level - Current: 0.950, New: 0.925\n",
            "\n",
            "🧮 DIEBOLD-MARIANO STATISTICAL TEST:\n",
            "Test Statistic: 1.5879\n",
            "P-value: 0.112312\n",
            "Significant at α=0.05: False\n",
            "Result: NO statistically significant difference\n",
            "\n",
            "💼 PRODUCTION DEPLOYMENT DECISION:\n",
            "Decision: ❌ DO NOT DEPLOY - Difference not statistically significant\n",
            "Risk Assessment: High risk - performance difference likely random noise\n",
            "Business Recommendation: No significant difference - consider other factors\n",
            "\n",
            "================================================================================\n",
            "KEY TAKEAWAYS:\n",
            "================================================================================\n",
            "1. MAE alone is insufficient for intermittent time series\n",
            "2. Use MASE, Hit Rate, and Service Level for business relevance\n",
            "3. ALWAYS validate with Diebold-Mariano before deployment\n",
            "4. Statistical significance prevents costly deployment mistakes\n",
            "5. Proper metrics align with inventory management objectives\n"
          ]
        }
      ]
    }
  ]
}